### Some GPT References

  

* [3 Reasons to How ChatGPT Became the Fastest Growing App of All Time](https://www.makeuseof.com/how-chatgpt-became-fastest-growing-app/)

* [chatGPT - Wikipedia](https://en.wikipedia.org/wiki/ChatGPT)

* [ChatGPT 101: What Is Generative Al (and How to Use It)](https://www.coursera.org/articles/chatgpt)

* [ChatGPT Cheatsheet](https://quickref.me/chatgpt)

* [ChatGPT could cost over $700,000 per day to operate](https://www.businessinsider.com/how-much-chatgpt-costs-openai-to-run-estimate-report-2023-4?op=1)

* [Generative pre-trained transformer - Wikipedia](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer)

* [GPT Wikipedia](https://en.wikipedia.org/wiki/GPT)

* [GPT-1 to GPT-4: Each of OpenAl's GPT Models Explained and Compared](https://www.makeuseof.com/gpt-models-explained-and-compared/)

* [GPT-4](https://en.wikipedia.org/wiki/GPT-4)

* [GPT-4 API Pricing Analysis](https://medium.com/sopmac-labs/gpt-4-api-pricing-analysis-a507a4bf9829)

* [GPT-4 has a trillion parameters - Report](https://the-decoder.com/gpt-4-has-a-trillion-parameters/)

* [GPT-4 Technical Report](https://deepai.org/publication/gpt-4-technical-report) - PDF file

* [How ChatGPT and Other LLMs Work-and Where They Could Go Next](https://www.wired.com/story/how-chatgpt-works-large-language-model/)

* [Microsoft spent hundreds of millions of...n a ChatGPT supercomputer The Verge](https://www.theverge.com/2023/3/13/23637675/microsoft-chatgpt-bing-millions-dollars-supercomputer-openai)

* [Nvidia reveals H100 GPU for AI](https://www.theverge.com/2022/3/22/22989182/nvidia-hopper-architecture-h100-gpu-eos-supercomputer)

* [OpenAI API Pricing in Words per Dollar](https://medium.com/sopmac-labs/openai-api-pricing-in-words-per-dollar-9eeac857aee7)

* [OpenAl's CEO Says the Age of Giant Al Models Is Already Over](https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/)

* [Parameter - Wikipedia](https://en.wikipedia.org/wiki/Parameter?wprov=srpw1_5)

* [Probability distribution - Wikipedia](https://en.wikipedia.org/wiki/Probability_distribution)

* [The Art of ChatGPT Prompting](https://fka.gumroad.com/l/art-of-chatgpt-prompting)

* [The future of generative Al is niche, not generalized](https://www.technologyreview.com/2023/04/27/1072102/the-future-of-generative-ai-is-niche-not-generalized)

* [You won’t believe how much ChatGPT costs to operate](https://www.digitaltrends.com/computing/chatgpt-cost-to-operate/)

* [What's AGI, and Why Are Al Experts Skeptical?](https://www.wired.com/story/what-is-artificial-general-intelligence-agi-explained/?redirectURL=https%3A%2F%2Fwww.wired.com%2Fstory%2Fwhat-is-artificial-general-intelligence-agi-explained%2F)

* [What Are Large Language Models (LLMs) and How Do They Work?](https://www.makeuseof.com/what-are-large-langauge-models-how-do-they-work/)

---

#### Andrej Karpathy

* [Andrej Karpathy - Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)

* [Andrej Karpathy - Let's build GPT: from scratch, in code, spelled out](https://www.youtube.com/watch?v=kCc8FmEb1nY)

- karpathy / nanoGPT: https://github.com/karpathy/nanoGPT/blob/master/model.py

- karpathy / lectures/micrograd : https://github.com/karpathy/nn-zero-to-hero/tree/master/lectures/micrograd

##### Links

Links:
- Google colab for the video: https://colab.research.google.com/dri...
- GitHub repo for the video: https://github.com/karpathy/ng-video-...
- Playlist of the whole Zero to Hero series so far:   

 • The spelled-out i...  
- nanoGPT repo: https://github.com/karpathy/nanoGPTx
- my website: https://karpathy.ai
- my twitter: https://twitter.com/karpathy
- our Discord channel: https://discord.gg/3zy8kqD9Cp

Supplementary links:
- Attention is All You Need paper: https://arxiv.org/abs/1706.03762
  - https://arxiv.org/pdf/1706.03762.pdf
  
- OpenAI GPT-3 paper: https://arxiv.org/abs/2005.14165 
  - https://arxiv.org/pdf/2005.14165.pdf

- OpenAI ChatGPT blog post: https://openai.com/blog/chatgpt/
  - Language models can explain neurons in language models: https://openai.com/research/language-models-can-explain-neurons-in-language-models
  - Training language models to follow instructions with human feedback: https://arxiv.org/pdf/2203.02155.pdf

  - InstructGPT: Training Language Models to Follow Instructions with Human Feedback  https://github.com/openai/following-instructions-human-feedback#instructgpt-training-language-models-to-follow-instructions-with-human-feedback

- The GPU I'm training the model on is from Lambda GPU Cloud, I think the best and easiest way to spin up an on-demand GPU instance in the cloud that you can ssh to: https://lambdalabs.com . If you prefer to work in notebooks, I think the easiest path today is Google Colab.

---

* [Transformers, explained: Understand the model behind GPT, BERT, and T5](https://www.youtube.com/watch?v=SZorAJ4I-sA)